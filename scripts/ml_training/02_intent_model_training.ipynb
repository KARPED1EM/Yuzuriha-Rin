{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d01f7da",
   "metadata": {},
   "source": [
    "# Intent Model Training\n",
    "This notebook retrains the transformer-based intent classifier that powers `src/services/behavior/sticker.py`. It consumes the artefacts created by the analysis notebook (or rebuilds them if needed), fine-tunes the model, evaluates it thoroughly, and persists everything under `assets/models/intent_predictor`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10258cd",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "1. Resolve project/root paths and hyperparameters.\n",
    "2. Load the cleaned dataset (or regenerate it from raw jsonl files).\n",
    "3. Visualize the training distribution for sanity checking.\n",
    "4. Tokenize data with the Hugging Face tokenizer and train via `Trainer`.\n",
    "5. Produce metrics, confusion matrices, and qualitative samples.\n",
    "6. Persist the model, tokenizer, mappings, metrics, and plots back to `assets/models/intent_predictor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e6a061",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "\n",
    "import torch\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "sns.set_theme(style=\"whitegrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"font.family\"] = [\"DejaVu Sans\", \"Arial\", \"sans-serif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afff6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path().resolve()\n",
    "\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for candidate in [start] + list(start.parents):\n",
    "        if (candidate / \"assets\" / \"models\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not locate project root\")\n",
    "\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "ASSETS_DIR = PROJECT_ROOT / \"assets\"\n",
    "MODELS_DIR = ASSETS_DIR / \"models\"\n",
    "DATA_DIR = MODELS_DIR / \"few_shot_intent_sft\" / \"data\"\n",
    "MODEL_DIR = MODELS_DIR / \"intent_predictor\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "PROCESSED_DATA_PATH = MODEL_DIR / \"clean_wechat_intents.parquet\"\n",
    "TRAINING_DATA_SNAPSHOT = MODEL_DIR / \"training_dataset_snapshot.parquet\"\n",
    "REPORT_PATH = MODEL_DIR / \"evaluation_metrics.json\"\n",
    "CLASSIFICATION_REPORT_PATH = MODEL_DIR / \"classification_report.csv\"\n",
    "CONFUSION_MATRIX_PATH = MODEL_DIR / \"confusion_matrix.png\"\n",
    "TRAINING_SUMMARY_PATH = MODEL_DIR / \"training_summary.json\"\n",
    "LABEL_MAPPING_PATH = MODEL_DIR / \"intent_mapping.json\"\n",
    "\n",
    "MODEL_NAME = \"hfl/chinese-bert-wwm-ext\"\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 4\n",
    "LEARNING_RATE = 2e-5\n",
    "TEST_SIZE = 0.2\n",
    "RANDOM_SEED = 42\n",
    "ENABLE_BACKUP = True\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Model output directory: {MODEL_DIR}\")\n",
    "print(f\"Processed dataset path: {PROCESSED_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2900393",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_INTENTS = {\n",
    "    \"查询类\",\n",
    "    \"查询(产品信息)\",\n",
    "    \"查询(价格)\",\n",
    "    \"查询(优惠)\",\n",
    "    \"查询(库存)\",\n",
    "    \"查询(物流)\",\n",
    "    \"查询(订单)\",\n",
    "    \"查询(账户)\",\n",
    "    \"查询(余额)\",\n",
    "    \"实体(产品)\",\n",
    "    \"实体(价格)\",\n",
    "    \"实体(时间)\",\n",
    "    \"实体(地点)\",\n",
    "    \"实体(人名)\",\n",
    "    \"实体(公司)\",\n",
    "    \"实体识别\",\n",
    "    \"产品推荐\",\n",
    "    \"促销活动\",\n",
    "    \"优惠信息\",\n",
    "    \"下单\",\n",
    "    \"支付\",\n",
    "    \"退款\",\n",
    "    \"投诉\",\n",
    "    \"售后\",\n",
    "    \"政治敏感\",\n",
    "    \"污言秽语\",\n",
    "    \"色情低俗\",\n",
    "    \"暴力血腥\",\n",
    "    \"违法犯罪\",\n",
    "    \"广告营销\",\n",
    "    \"诈骗信息\",\n",
    "    \"肯定(没问题)\",\n",
    "    \"否定(没有)\",\n",
    "    \"转人工\",\n",
    "    \"挂断电话\",\n",
    "    \"保持通话\",\n",
    "    \"重复\",\n",
    "    \"澄清\",\n",
    "    \"确认信息\",\n",
    "    \"核实身份\",\n",
    "    \"录音提示\",\n",
    "    \"系统提示\",\n",
    "}\n",
    "\n",
    "RAW_DATASETS = [\n",
    "    (\"telemarketing\", DATA_DIR / \"telemarketing_intent_cn.jsonl\"),\n",
    "    (\"crosswoz\", DATA_DIR / \"crosswoz.jsonl\"),\n",
    "]\n",
    "\n",
    "\n",
    "def read_jsonl(path: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def load_or_build_dataset() -> pd.DataFrame:\n",
    "    if PROCESSED_DATA_PATH.exists():\n",
    "        print(f\"Loading cached dataset from {PROCESSED_DATA_PATH}\")\n",
    "        df = pd.read_parquet(PROCESSED_DATA_PATH)\n",
    "        df[\"dataset\"].fillna(\"telemarketing\", inplace=True)\n",
    "        return df\n",
    "\n",
    "    frames = []\n",
    "    for name, path in RAW_DATASETS:\n",
    "        if not path.exists():\n",
    "            print(f\"Skipping {name}: {path} not found\")\n",
    "            continue\n",
    "        df = read_jsonl(path)\n",
    "        df[\"dataset\"] = name\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No raw datasets available. Please populate assets/models/few_shot_intent_sft/data\")\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "    merged[\"text\"] = merged[\"text\"].astype(str)\n",
    "    cleaned = merged[~merged[\"label\"].isin(BLACKLIST_INTENTS)].copy()\n",
    "    label_counts = cleaned[\"label\"].value_counts()\n",
    "    keep_labels = label_counts[label_counts >= 20].index\n",
    "    cleaned = cleaned[cleaned[\"label\"].isin(keep_labels)].copy()\n",
    "\n",
    "    capped_parts = []\n",
    "    for label, group in cleaned.groupby(\"label\"):\n",
    "        if len(group) > 300:\n",
    "            sample = group.sample(n=300, random_state=RANDOM_SEED)\n",
    "        else:\n",
    "            sample = group\n",
    "        capped_parts.append(sample)\n",
    "    capped = pd.concat(capped_parts, ignore_index=True)\n",
    "    capped = capped.sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    capped[\"text_length\"] = capped[\"text\"].str.len()\n",
    "    capped.to_parquet(PROCESSED_DATA_PATH, index=False)\n",
    "    print(f\"Cached dataset saved to {PROCESSED_DATA_PATH}\")\n",
    "    return capped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40201a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = load_or_build_dataset()\n",
    "print(f\"Dataset shape: {dataset_df.shape}\")\n",
    "print(f\"Unique intents: {dataset_df['label'].nunique()}\")\n",
    "\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdddfbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_counts = dataset_df[\"label\"].value_counts()\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x=intent_counts.head(30).values, y=intent_counts.head(30).index)\n",
    "plt.title(\"Top intents after preprocessing\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Intent\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "sns.histplot(dataset_df[\"text\"].str.len(), bins=40, color=\"#8b5cf6\")\n",
    "plt.title(\"Character length distribution\")\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8fc403",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = sorted(dataset_df[\"label\"].unique())\n",
    "intent2id = {label: idx for idx, label in enumerate(labels)}\n",
    "id2intent = {idx: label for label, idx in intent2id.items()}\n",
    "\n",
    "dataset_df[\"label_id\"] = dataset_df[\"label\"].map(intent2id)\n",
    "\n",
    "train_df, test_df = train_test_split(\n",
    "    dataset_df,\n",
    "    test_size=TEST_SIZE,\n",
    "    random_state=RANDOM_SEED,\n",
    "    stratify=dataset_df[\"label_id\"],\n",
    ")\n",
    "\n",
    "print(f\"Train rows: {len(train_df):,}\")\n",
    "print(f\"Test rows: {len(test_df):,}\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe62bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(df: pd.DataFrame) -> Dataset:\n",
    "    return Dataset.from_pandas(df[[\"text\", \"label_id\"]].rename(columns={\"label_id\": \"label\"}))\n",
    "\n",
    "\n",
    "hf_dataset = DatasetDict(\n",
    "    {\n",
    "        \"train\": dataframe_to_dataset(train_df),\n",
    "        \"test\": dataframe_to_dataset(test_df),\n",
    "    }\n",
    ")\n",
    "\n",
    "hf_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f987ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    num_labels=len(intent2id),\n",
    ")\n",
    "model.config.id2label = id2intent\n",
    "model.config.label2id = intent2id\n",
    "\n",
    "\n",
    "def tokenize_function(batch):\n",
    "    return tokenizer(\n",
    "        batch[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "\n",
    "encoded_dataset = hf_dataset.map(tokenize_function, batched=True)\n",
    "encoded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343eec93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, preds),\n",
    "        \"f1_weighted\": f1_score(labels, preds, average=\"weighted\"),\n",
    "    }\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=str(MODEL_DIR / \"checkpoints\"),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE * 2,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    report_to=\"none\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1_weighted\",\n",
    "    greater_is_better=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=encoded_dataset[\"train\"],\n",
    "    eval_dataset=encoded_dataset[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "train_result = trainer.train()\n",
    "train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea95f6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_metrics = trainer.evaluate()\n",
    "print(\"Evaluation metrics:\")\n",
    "for key, value in eval_metrics.items():\n",
    "    if isinstance(value, (int, float)):\n",
    "        print(f\"  {key}: {value:.4f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "test_predictions = trainer.predict(encoded_dataset[\"test\"])\n",
    "pred_labels = np.argmax(test_predictions.predictions, axis=-1)\n",
    "true_labels = test_predictions.label_ids\n",
    "\n",
    "report = classification_report(\n",
    "    true_labels,\n",
    "    pred_labels,\n",
    "    target_names=[id2intent[i] for i in range(len(id2intent))],\n",
    "    zero_division=0,\n",
    "    output_dict=True,\n",
    ")\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d988f645",
   "metadata": {},
   "source": [
    "### Confusion matrix and per-intent F1\n",
    "Visual diagnostics help catch degenerate classes and guide data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5842f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(true_labels, pred_labels, labels=list(range(len(intent2id))))\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, cmap=\"rocket_r\", linewidths=0.1)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted label id\")\n",
    "plt.ylabel(\"True label id\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "per_intent = report_df.drop(index=[\"accuracy\", \"macro avg\", \"weighted avg\"], errors=\"ignore\")\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.barplot(x=per_intent.index, y=per_intent[\"f1-score\"], palette=\"crest\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylim(0, 1)\n",
    "plt.title(\"Per-intent F1 score\")\n",
    "plt.ylabel(\"F1 score\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d1859e",
   "metadata": {},
   "source": [
    "### Hardest samples\n",
    "Review a few mismatches sorted by confidence gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8658543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = torch.nn.functional.softmax(torch.tensor(test_predictions.predictions), dim=-1).numpy()\n",
    "confidences = probs[np.arange(len(pred_labels)), pred_labels]\n",
    "\n",
    "error_mask = pred_labels != true_labels\n",
    "errors_df = pd.DataFrame(\n",
    "    {\n",
    "        \"text\": test_df.reset_index(drop=True).loc[error_mask, \"text\"],\n",
    "        \"true_intent\": [id2intent[idx] for idx in true_labels[error_mask]],\n",
    "        \"pred_intent\": [id2intent[idx] for idx in pred_labels[error_mask]],\n",
    "        \"confidence\": confidences[error_mask],\n",
    "    }\n",
    ")\n",
    "\n",
    "errors_df.sort_values(\"confidence\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db1ed6ef",
   "metadata": {},
   "source": [
    "### Persist artefacts\n",
    "The sticker service expects the model, tokenizer, and `intent_mapping.json` inside `assets/models/intent_predictor`. Metrics and plots are stored alongside for quick auditing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e293eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if ENABLE_BACKUP and MODEL_DIR.exists() and any(MODEL_DIR.iterdir()):\n",
    "    backup_dir = MODEL_DIR.parent / \"intent_predictor_backups\"\n",
    "    backup_dir.mkdir(parents=True, exist_ok=True)\n",
    "    timestamp = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    snapshot_path = backup_dir / f\"intent_predictor_{timestamp}\"\n",
    "    if snapshot_path.exists():\n",
    "        shutil.rmtree(snapshot_path)\n",
    "    shutil.copytree(MODEL_DIR, snapshot_path)\n",
    "    print(f\"Existing model backed up to {snapshot_path}\")\n",
    "\n",
    "trainer.save_model(str(MODEL_DIR))\n",
    "tokenizer.save_pretrained(str(MODEL_DIR))\n",
    "\n",
    "data_snapshot = pd.concat([train_df, test_df], ignore_index=True)\n",
    "data_snapshot.to_parquet(TRAINING_DATA_SNAPSHOT, index=False)\n",
    "\n",
    "mapping_payload = {\n",
    "    \"intent2id\": intent2id,\n",
    "    \"id2intent\": {str(k): v for k, v in id2intent.items()},\n",
    "}\n",
    "with open(LABEL_MAPPING_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(mapping_payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "report_df.to_csv(CLASSIFICATION_REPORT_PATH)\n",
    "\n",
    "metrics_payload = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"model_name\": MODEL_NAME,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"max_length\": MAX_LENGTH,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"learning_rate\": LEARNING_RATE,\n",
    "    \"train_size\": len(train_df),\n",
    "    \"test_size\": len(test_df),\n",
    "    \"num_labels\": len(intent2id),\n",
    "    \"eval\": {k: float(v) if isinstance(v, (int, float, np.floating)) else v for k, v in eval_metrics.items()},\n",
    "}\n",
    "with open(REPORT_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics_payload, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "with open(TRAINING_SUMMARY_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(\n",
    "        {\n",
    "            \"intent_count\": len(intent2id),\n",
    "            \"train_rows\": len(train_df),\n",
    "            \"test_rows\": len(test_df),\n",
    "        },\n",
    "        f,\n",
    "        indent=2,\n",
    "    )\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(cm, cmap=\"rocket_r\", linewidths=0.1)\n",
    "plt.title(\"Confusion matrix\")\n",
    "plt.xlabel(\"Predicted label id\")\n",
    "plt.ylabel(\"True label id\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(CONFUSION_MATRIX_PATH)\n",
    "plt.close()\n",
    "\n",
    "print(f\"Model + tokenizer saved to: {MODEL_DIR}\")\n",
    "print(f\"Metrics saved to: {REPORT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8430562",
   "metadata": {},
   "source": [
    "### Quick inference sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2aacbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_tokenizer = AutoTokenizer.from_pretrained(str(MODEL_DIR))\n",
    "predictor_model = AutoModelForSequenceClassification.from_pretrained(str(MODEL_DIR))\n",
    "\n",
    "sample_texts = [\n",
    "    \"你好呀，等下聊聊？\",\n",
    "    \"我这会儿不方便接电话\",\n",
    "    \"地址可以发一下吗？\",\n",
    "]\n",
    "\n",
    "inputs = predictor_tokenizer(\n",
    "    sample_texts,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=MAX_LENGTH,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "with torch.no_grad():\n",
    "    logits = predictor_model(**inputs).logits\n",
    "    probs = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    confidences, label_ids = torch.max(probs, dim=-1)\n",
    "\n",
    "results = []\n",
    "for text, label_id, confidence in zip(sample_texts, label_ids.tolist(), confidences.tolist()):\n",
    "    results.append(\n",
    "        {\n",
    "            \"text\": text,\n",
    "            \"intent\": id2intent[label_id],\n",
    "            \"confidence\": round(float(confidence), 4),\n",
    "        }\n",
    "    )\n",
    "\n",
    "pd.DataFrame(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
