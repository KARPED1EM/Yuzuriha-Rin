{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c6c173",
   "metadata": {},
   "source": [
    "# Intent Data Analysis\n",
    "This notebook inspects the raw intent corpora powering the sticker selection model. It focuses on understanding label coverage, pruning noisy intents, and producing summary artefacts used during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b4bf6d",
   "metadata": {},
   "source": [
    "## What you will find here\n",
    "- Automatic project-path discovery so the notebook works from anywhere in the repo.\n",
    "- Data ingestion for `telemarketing_intent_cn.jsonl` plus the optional `crosswoz.jsonl` corpus.\n",
    "- Exploratory analysis (statistics, tables, charts) to inspect intent coverage and message length patterns.\n",
    "- Filtering utilities (blacklist removal, minimum sample threshold, balanced sampling) to produce a clean dataset.\n",
    "- Persistence of cleaned data and label reports under `assets/models/intent_predictor` for downstream notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3723c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 100)\n",
    "pd.set_option(\"display.max_columns\", 50)\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\", context=\"notebook\")\n",
    "plt.rcParams[\"figure.figsize\"] = (11, 6)\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.rcParams[\"font.family\"] = [\"DejaVu Sans\", \"Arial\", \"sans-serif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ca1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NOTEBOOK_DIR = Path().resolve()\n",
    "\n",
    "def find_project_root(start: Path) -> Path:\n",
    "    for candidate in [start] + list(start.parents):\n",
    "        if (candidate / \"assets\" / \"models\").exists():\n",
    "            return candidate\n",
    "    raise RuntimeError(\"Could not find project root (missing assets/models)\")\n",
    "\n",
    "PROJECT_ROOT = find_project_root(NOTEBOOK_DIR)\n",
    "ASSETS_DIR = PROJECT_ROOT / \"assets\"\n",
    "MODELS_DIR = ASSETS_DIR / \"models\"\n",
    "DATA_DIR = MODELS_DIR / \"few_shot_intent_sft\" / \"data\"\n",
    "MODEL_DIR = MODELS_DIR / \"intent_predictor\"\n",
    "MODEL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TELEMARKETING_DATA = DATA_DIR / \"telemarketing_intent_cn.jsonl\"\n",
    "CROSSWOZ_DATA = DATA_DIR / \"crosswoz.jsonl\"\n",
    "\n",
    "PROCESSED_DATA_PATH = MODEL_DIR / \"clean_wechat_intents.parquet\"\n",
    "LABEL_COUNTS_PATH = MODEL_DIR / \"label_distribution.csv\"\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "MIN_SAMPLES = 20\n",
    "MAX_SAMPLES_PER_INTENT = 300\n",
    "USE_CROSSWOZ = True\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")\n",
    "print(f\"Raw data directory: {DATA_DIR}\")\n",
    "print(f\"Artifacts will be stored in: {MODEL_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f001e60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACKLIST_INTENTS = {\n",
    "    \"查询类\",\n",
    "    \"查询(产品信息)\",\n",
    "    \"查询(价格)\",\n",
    "    \"查询(优惠)\",\n",
    "    \"查询(库存)\",\n",
    "    \"查询(物流)\",\n",
    "    \"查询(订单)\",\n",
    "    \"查询(账户)\",\n",
    "    \"查询(余额)\",\n",
    "    \"实体(产品)\",\n",
    "    \"实体(价格)\",\n",
    "    \"实体(时间)\",\n",
    "    \"实体(地点)\",\n",
    "    \"实体(人名)\",\n",
    "    \"实体(公司)\",\n",
    "    \"实体识别\",\n",
    "    \"产品推荐\",\n",
    "    \"促销活动\",\n",
    "    \"优惠信息\",\n",
    "    \"下单\",\n",
    "    \"支付\",\n",
    "    \"退款\",\n",
    "    \"投诉\",\n",
    "    \"售后\",\n",
    "    \"政治敏感\",\n",
    "    \"污言秽语\",\n",
    "    \"色情低俗\",\n",
    "    \"暴力血腥\",\n",
    "    \"违法犯罪\",\n",
    "    \"广告营销\",\n",
    "    \"诈骗信息\",\n",
    "    \"肯定(没问题)\",\n",
    "    \"否定(没有)\",\n",
    "    \"转人工\",\n",
    "    \"挂断电话\",\n",
    "    \"保持通话\",\n",
    "    \"重复\",\n",
    "    \"澄清\",\n",
    "    \"确认信息\",\n",
    "    \"核实身份\",\n",
    "    \"录音提示\",\n",
    "    \"系统提示\",\n",
    "}\n",
    "\n",
    "RAW_DATASETS = [\n",
    "    (\"telemarketing\", TELEMARKETING_DATA),\n",
    "    (\"crosswoz\", CROSSWOZ_DATA),\n",
    "]\n",
    "\n",
    "\n",
    "def read_jsonl(path: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            rows.append(json.loads(line))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "def load_raw_dataset() -> pd.DataFrame:\n",
    "    frames = []\n",
    "    for name, path in RAW_DATASETS:\n",
    "        if not path.exists():\n",
    "            print(f\"Skipping {name}: {path} not found\")\n",
    "            continue\n",
    "        df = read_jsonl(path)\n",
    "        df[\"dataset\"] = name\n",
    "        frames.append(df)\n",
    "    if not frames:\n",
    "        raise FileNotFoundError(\"No datasets available. Please place jsonl files in assets/models/few_shot_intent_sft/data\")\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "    merged = merged.rename(columns={\"text\": \"text\", \"label\": \"label\"})\n",
    "    merged[\"text\"] = merged[\"text\"].astype(str)\n",
    "    return merged\n",
    "\n",
    "\n",
    "def apply_filters(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    filtered = df[~df[\"label\"].isin(BLACKLIST_INTENTS)].copy()\n",
    "    label_counts = filtered[\"label\"].value_counts()\n",
    "    keep_labels = label_counts[label_counts >= MIN_SAMPLES].index\n",
    "    filtered = filtered[filtered[\"label\"].isin(keep_labels)].copy()\n",
    "    filtered[\"text_length\"] = filtered[\"text\"].str.len()\n",
    "    return filtered\n",
    "\n",
    "\n",
    "def balance_dataset(df: pd.DataFrame, max_samples: int) -> pd.DataFrame:\n",
    "    balanced_parts = []\n",
    "    for label, group in df.groupby(\"label\"):\n",
    "        if len(group) > max_samples:\n",
    "            sample = group.sample(n=max_samples, random_state=RANDOM_SEED)\n",
    "        else:\n",
    "            sample = group\n",
    "        balanced_parts.append(sample)\n",
    "    balanced = pd.concat(balanced_parts, ignore_index=True)\n",
    "    balanced = balanced.sample(frac=1.0, random_state=RANDOM_SEED).reset_index(drop=True)\n",
    "    balanced[\"text_length\"] = balanced[\"text\"].str.len()\n",
    "    return balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674e23a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = load_raw_dataset()\n",
    "print(f\"Loaded {len(raw_df):,} rows from {raw_df['dataset'].nunique()} datasets\")\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_summary = (\n",
    "    raw_df.groupby(\"dataset\")\n",
    "    .agg(samples=(\"text\", \"count\"), unique_labels=(\"label\", \"nunique\"))\n",
    "    .sort_values(\"samples\", ascending=False)\n",
    ")\n",
    "raw_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc0bdf5",
   "metadata": {},
   "source": [
    "### Clean and balance the dataset\n",
    "1. Remove intents on the blacklist that do not fit the WeChat chat use case.\n",
    "2. Drop intents with fewer than `MIN_SAMPLES` examples.\n",
    "3. Cap large classes to `MAX_SAMPLES_PER_INTENT` to avoid bias.\n",
    "4. Shuffle to avoid unintentional ordering artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23dbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = apply_filters(raw_df)\n",
    "balanced_df = balance_dataset(filtered_df, MAX_SAMPLES_PER_INTENT)\n",
    "\n",
    "print(f\"Filtered dataset: {len(filtered_df):,} rows · {filtered_df['label'].nunique()} intents\")\n",
    "print(f\"Balanced dataset: {len(balanced_df):,} rows · {balanced_df['label'].nunique()} intents\")\n",
    "\n",
    "balanced_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b76afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_counts = balanced_df[\"label\"].value_counts()\n",
    "length_stats = balanced_df[\"text_length\"].describe()\n",
    "\n",
    "print(\"Length (chars) stats:\")\n",
    "print(length_stats)\n",
    "\n",
    "intent_counts.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66d4698",
   "metadata": {},
   "source": [
    "### Label distribution (top 30 intents)\n",
    "The bar plot highlights the top intents after filtering and balancing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6c68a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 30\n",
    "plot_series = intent_counts.head(top_n)[::-1]\n",
    "plt.figure(figsize=(10, 12))\n",
    "sns.barplot(x=plot_series.values, y=plot_series.index, palette=\"viridis\")\n",
    "plt.title(f\"Top {top_n} intents by sample count\")\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Intent\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561d2c66",
   "metadata": {},
   "source": [
    "### Text length overview\n",
    "Character-length histograms and per-dataset box plots help us understand complexity and tailor truncation length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f7014",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(balanced_df[\"text_length\"], bins=40, kde=True, color=\"#3b82f6\")\n",
    "plt.axvline(balanced_df[\"text_length\"].median(), color=\"red\", linestyle=\"--\", label=\"median\")\n",
    "plt.title(\"Message length distribution\")\n",
    "plt.xlabel(\"Characters per message\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=balanced_df, x=\"dataset\", y=\"text_length\", palette=\"Set2\")\n",
    "plt.title(\"Length spread per source dataset\")\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Characters\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf9a407",
   "metadata": {},
   "source": [
    "### Dataset vs intent heatmap\n",
    "The heatmap highlights which intents originate from which dataset, revealing potential coverage gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc0c1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = (\n",
    "    balanced_df.groupby([\"dataset\", \"label\"])\n",
    "    .size()\n",
    "    .unstack(fill_value=0)\n",
    ")\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(\n",
    "    pivot,\n",
    "    cmap=\"YlGnBu\",\n",
    "    cbar_kws={\"label\": \"Samples\"},\n",
    "    linewidths=0.5,\n",
    ")\n",
    "plt.title(\"Dataset contribution heatmap\")\n",
    "plt.xlabel(\"Intent\")\n",
    "plt.ylabel(\"Dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d478db9",
   "metadata": {},
   "source": [
    "### Persist processed data for reuse\n",
    "Saving the balanced dataset speeds up repeated experiments and keeps `assets/models/intent_predictor` self-contained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e4a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.to_parquet(PROCESSED_DATA_PATH, index=False)\n",
    "intent_counts.to_csv(LABEL_COUNTS_PATH, header=[\"samples\"])\n",
    "\n",
    "print(f\"Processed dataset saved to: {PROCESSED_DATA_PATH}\")\n",
    "print(f\"Label distribution saved to: {LABEL_COUNTS_PATH}\")\n",
    "print(f\"Timestamp: {datetime.utcnow().isoformat()}Z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d82bb10",
   "metadata": {},
   "source": [
    "### Quick samples\n",
    "Use this cell to inspect a few random rows whenever you re-run the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df.sample(5, random_state=RANDOM_SEED)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
